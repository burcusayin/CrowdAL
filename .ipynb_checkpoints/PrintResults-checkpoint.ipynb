{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTS - Scenario 2\n",
    "\n",
    "\n",
    "### Recognizing Textual Entailment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "resplot = Results()\n",
    "resplot.readResult('rte_maxVote3')\n",
    "result = resplot.printResults()\n",
    "results['rte_maxVote3'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion - Anger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resplot = Results() \n",
    "resplot.readResult('emotion_maxVote3')\n",
    "result = resplot.printResults()\n",
    "results['emotion_maxVote3'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Sentiment Dataset - \"Does this abstract belongs to a book?\" predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resplot = Results() \n",
    "resplot.readResult('amazon_isBook_maxVote3')\n",
    "result = resplot.printResults()\n",
    "results['amazon_isBook_maxVote3'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Sentiment Dataset - \"Does this abstract have a negative sentiment?\" predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resplot = Results()  \n",
    "resplot.readResult('amazon_isNegative_maxVote3')\n",
    "result = resplot.printResults()\n",
    "results['amazon_isNegative_maxVote3'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crisis: Practical Extraction of Disaster-Relevant Information from Social Media Dataset - \"The author of the tweet seems to be an eye witness of the event?\" predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resplot = Results() \n",
    "resplot.readResult('crisis_author_maxVote3')\n",
    "result = resplot.printResults()\n",
    "results['crisis_author_maxVote3'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crisis: Practical Extraction of Disaster-Relevant Information from Social Media Dataset - \"What is the type of the message?\" predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resplot = Results() \n",
    "resplot.readResult('crisis_message_maxVote3')\n",
    "result = resplot.printResults()\n",
    "results['crisis_message_maxVote3'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crisis: Practical Extraction of Disaster-Relevant Information from Social Media - Determine The Type Of A Hurricane-Related Tweet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resplot = Results()\n",
    "resplot.readResult('crisis_type_maxVote3')\n",
    "result = resplot.printResults()\n",
    "results['crisis_type_maxVote3'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exergame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resplot = Results()\n",
    "resplot.readResult('exergame_maxVote3')\n",
    "result = resplot.printResults()\n",
    "results['exergame_maxVote3'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "import xlsxwriter \n",
    "workbook = xlsxwriter.Workbook('results_maxVote3.xlsx')  \n",
    "#datasets = ['rte_combined', 'emotion_combined', 'amazon_isBook_combined', 'amazon_isNegative_combined', 'crisis_author_combined', 'crisis_message_combined', 'crisis_type_combined']\n",
    "datasets = ['rte_maxVote3', 'emotion_maxVote3', 'amazon_isBook_maxVote3', 'amazon_isNegative_maxVote3', 'crisis_author_maxVote3', 'crisis_message_maxVote3', 'crisis_type_maxVote3', 'exergame_maxVote3']\n",
    "algos = ['random', 'uncertainty', 'certainty', 'block-certainty-1', 'quire', 'lal-rand', 'lal-iter']\n",
    "#algos = ['minExpError'] \n",
    "\n",
    "wsAcc = workbook.add_worksheet(\"accuracy\")\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for algo in algos:\n",
    "    row +=1\n",
    "    wsAcc.write(row, col, algo)\n",
    "\n",
    "row = 0\n",
    "for dataset in datasets:\n",
    "    col +=2\n",
    "    wsAcc.write(row, col, dataset)\n",
    "\n",
    "row = 1\n",
    "col = 1\n",
    "\n",
    "for algo in algos: \n",
    "    for dataset in datasets:\n",
    "        # write operation perform \n",
    "        wsAcc.write(row, col, round(results[dataset][algo]['accuracy1'], 2)) \n",
    "        col +=1\n",
    "        wsAcc.write(row, col, round(results[dataset][algo]['accuracy2'], 2)) \n",
    "        col +=1\n",
    "    row += 1\n",
    "    col = 1\n",
    "\n",
    "wsF1 = workbook.add_worksheet(\"F1\")\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for algo in algos:\n",
    "    row +=1\n",
    "    wsF1.write(row, col, algo)\n",
    "\n",
    "row = 0\n",
    "for dataset in datasets:\n",
    "    col +=2\n",
    "    wsF1.write(row, col, dataset)\n",
    "\n",
    "row = 1\n",
    "col = 1\n",
    "\n",
    "for algo in algos: \n",
    "    for dataset in datasets:\n",
    "        # write operation perform \n",
    "        wsF1.write(row, col, round(results[dataset][algo]['fbeta11'], 2)) \n",
    "        col +=1\n",
    "        wsF1.write(row, col, round(results[dataset][algo]['fbeta12'], 2)) \n",
    "        col +=1\n",
    "    row += 1\n",
    "    col = 1\n",
    "    \n",
    "wsF3 = workbook.add_worksheet(\"F3\")\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for algo in algos:\n",
    "    row +=1\n",
    "    wsF3.write(row, col, algo)\n",
    "\n",
    "row = 0\n",
    "for dataset in datasets:\n",
    "    col +=2\n",
    "    wsF3.write(row, col, dataset)\n",
    "\n",
    "row = 1\n",
    "col = 1\n",
    "\n",
    "for algo in algos: \n",
    "    for dataset in datasets:\n",
    "        # write operation perform \n",
    "        wsF3.write(row, col, round(results[dataset][algo]['fbeta31'], 2)) \n",
    "        col +=1\n",
    "        wsF3.write(row, col, round(results[dataset][algo]['fbeta32'], 2)) \n",
    "        col +=1\n",
    "    row += 1\n",
    "    col = 1\n",
    "    \n",
    "# Cost (K= 100)\n",
    "algos = ['random', 'uncertainty', 'certainty', 'block-certainty-100', 'quire', 'lal-rand', 'lal-iter']\n",
    "wsC100 = workbook.add_worksheet(\"Cost (K=100)\")\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for algo in algos:\n",
    "    row +=1\n",
    "    wsC100.write(row, col, algo)\n",
    "\n",
    "row = 0\n",
    "for dataset in datasets:\n",
    "    col +=2\n",
    "    wsC100.write(row, col, dataset)\n",
    "row = 1\n",
    "col = 1\n",
    "\n",
    "for algo in algos: \n",
    "    for dataset in datasets:\n",
    "        # write operation perform \n",
    "        wsC100.write(row, col, round(results[dataset][algo]['cost1_100'], 2)) \n",
    "        col +=1\n",
    "        wsC100.write(row, col, round(results[dataset][algo]['cost2_100'], 2)) \n",
    "        col +=1\n",
    "    row += 1\n",
    "    col = 1\n",
    "\n",
    "# Cost (K= 10)\n",
    "algos = ['random', 'uncertainty', 'certainty', 'block-certainty-10', 'quire', 'lal-rand', 'lal-iter']\n",
    "wsC10 = workbook.add_worksheet(\"Cost (K=10)\")\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for algo in algos:\n",
    "    row +=1\n",
    "    wsC10.write(row, col, algo)\n",
    "\n",
    "row = 0\n",
    "for dataset in datasets:\n",
    "    col +=2\n",
    "    wsC10.write(row, col, dataset)\n",
    "\n",
    "row = 1\n",
    "col = 1\n",
    "\n",
    "for algo in algos: \n",
    "    for dataset in datasets:\n",
    "        # write operation perform \n",
    "        wsC10.write(row, col, round(results[dataset][algo]['cost1_10'], 2)) \n",
    "        col +=1\n",
    "        wsC10.write(row, col, round(results[dataset][algo]['cost2_10'], 2)) \n",
    "        col +=1\n",
    "    row += 1\n",
    "    col = 1\n",
    "    \n",
    "# Cost (K= 1)\n",
    "algos = ['random', 'uncertainty', 'certainty', 'block-certainty-1', 'quire', 'lal-rand', 'lal-iter']\n",
    "wsC1 = workbook.add_worksheet(\"Cost (K=1)\")\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for algo in algos:\n",
    "    row +=1\n",
    "    wsC1.write(row, col, algo)\n",
    "\n",
    "row = 0\n",
    "for dataset in datasets:\n",
    "    col +=2\n",
    "    wsC1.write(row, col, dataset)\n",
    "\n",
    "row = 1\n",
    "col = 1\n",
    "\n",
    "for algo in algos: \n",
    "    for dataset in datasets:\n",
    "        # write operation perform \n",
    "        wsC1.write(row, col, round(results[dataset][algo]['cost1_1'], 2)) \n",
    "        col +=1\n",
    "        wsC1.write(row, col, round(results[dataset][algo]['cost2_1'], 2)) \n",
    "        col +=1\n",
    "    row += 1\n",
    "    col = 1\n",
    "    \n",
    "# Cost (K= 0.1)\n",
    "algos = ['random', 'uncertainty', 'certainty', 'block-certainty-01', 'quire', 'lal-rand', 'lal-iter']\n",
    "wsC01 = workbook.add_worksheet(\"Cost (K=0.1)\")\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for algo in algos:\n",
    "    row +=1\n",
    "    wsC01.write(row, col, algo)\n",
    "\n",
    "row = 0\n",
    "for dataset in datasets:\n",
    "    col +=2\n",
    "    wsC01.write(row, col, dataset)\n",
    "\n",
    "row = 1\n",
    "col = 1\n",
    "\n",
    "for algo in algos: \n",
    "    for dataset in datasets:\n",
    "        # write operation perform \n",
    "        wsC01.write(row, col, round(results[dataset][algo]['cost1_0.1'], 2)) \n",
    "        col +=1\n",
    "        wsC01.write(row, col, round(results[dataset][algo]['cost2_0.1'], 2)) \n",
    "        col +=1\n",
    "    row += 1\n",
    "    col = 1\n",
    "    \n",
    "# Cost (K= 0.01)\n",
    "algos = ['random', 'uncertainty', 'certainty', 'block-certainty-001', 'quire', 'lal-rand', 'lal-iter']\n",
    "wsC001 = workbook.add_worksheet(\"Cost (K=0.01)\")\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for algo in algos:\n",
    "    row +=1\n",
    "    wsC001.write(row, col, algo)\n",
    "\n",
    "row = 0\n",
    "for dataset in datasets:\n",
    "    col +=2\n",
    "    wsC001.write(row, col, dataset)\n",
    "\n",
    "row = 1\n",
    "col = 1\n",
    "\n",
    "for algo in algos: \n",
    "    for dataset in datasets:\n",
    "        # write operation perform \n",
    "        wsC001.write(row, col, round(results[dataset][algo]['cost1_0.01'], 2)) \n",
    "        col +=1\n",
    "        wsC001.write(row, col, round(results[dataset][algo]['cost2_0.01'], 2)) \n",
    "        col +=1\n",
    "    row += 1\n",
    "    col = 1\n",
    "    \n",
    "# num of classified items\n",
    "#algos = ['random', 'uncertainty', 'certainty', 'block-certainty-1', 'quire', 'lal-rand', 'lal-iter', 'minExpError']\n",
    "wsClf = workbook.add_worksheet(\"#OfClfITems\")\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for algo in algos:\n",
    "    row +=1\n",
    "    wsClf.write(row, col, algo)\n",
    "row = 0    \n",
    "for dataset in datasets:\n",
    "    col +=1\n",
    "    wsClf.write(row, col, dataset)\n",
    "\n",
    "row = 1\n",
    "col = 1\n",
    "\n",
    "for algo in algos: \n",
    "    for dataset in datasets:\n",
    "        # write operation perform \n",
    "        wsClf.write(row, col, round(results[dataset][algo]['numOfTrainedItems'], 2)) \n",
    "        col +=1\n",
    "    row += 1\n",
    "    col = 1\n",
    "\n",
    "workbook.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
